"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[5319],{4633:(e,t,a)=>{a.d(t,{Z:()=>r});var s=a(7294),d=a(3725),n=a(2263);const r=function(e){var t=e.apiPath,a=e.children,r=(0,d.useDocsVersion)(),i=(0,n.default)().siteConfig;return s.createElement("a",{href:i.baseUrl+"api/"+("current"===r.version?"next":r.version)+"/"+t},a)}},4680:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>u,contentTitle:()=>c,default:()=>h,frontMatter:()=>l,metadata:()=>p,toc:()=>m});var s=a(7462),d=a(3366),n=(a(7294),a(3905)),r=a(1736),i=a(4633);var o=["components"],l={id:"add-data-to-dataset",title:"Add data to dataset"},c=void 0,p={unversionedId:"examples/basics/add-data-to-dataset",id:"examples/basics/add-data-to-dataset",title:"Add data to dataset",description:"This example saves data to the default dataset. If the dataset doesn't exist, it will be created.",source:"@site/../docs/examples/basics/add_data_to_dataset.mdx",sourceDirName:"examples/basics",slug:"/examples/basics/add-data-to-dataset",permalink:"/apify-ts/docs/next/examples/basics/add-data-to-dataset",tags:[],version:"current",lastUpdatedBy:"Martin Ad\xe1mek",lastUpdatedAt:1646758386,formattedLastUpdatedAt:"3/8/2022",frontMatter:{id:"add-data-to-dataset",title:"Add data to dataset"},sidebar:"docs",previous:{title:"Accept user input",permalink:"/apify-ts/docs/next/examples/basics/accept-user-input"},next:{title:"Crawl a single URL",permalink:"/apify-ts/docs/next/examples/crawl-single-url"}},u={},m=[],w={toc:m};function h(e){var t=e.components,a=(0,d.Z)(e,o);return(0,n.kt)("wrapper",(0,s.Z)({},w,a,{components:t,mdxType:"MDXLayout"}),(0,n.kt)("p",null,"This example saves data to the default dataset. If the dataset doesn't exist, it will be created.\nYou can save data to custom datasets by using ",(0,n.kt)(i.Z,{apiPath:"core/class/Dataset#open",mdxType:"VersionedApiLink"},(0,n.kt)("inlineCode",{parentName:"p"},"Dataset.open()"))),(0,n.kt)(r.Z,{className:"language-js",mdxType:"CodeBlock"},"import { Dataset, CheerioCrawler } from '@crawlers/cheerio';\n\n// Create a dataset where we will store the results.\nconst dataset = await Dataset.open();\n\nconst crawler = new CheerioCrawler({\n    // Function called for each URL\n    async requestHandler({ request, body }) {\n        // Save data to default dataset\n        await dataset.pushData({\n            url: request.url,\n            html: body,\n        });\n    },\n});\n\nawait crawler.addRequests([\n    { url: 'http://www.example.com/page-1' },\n    { url: 'http://www.example.com/page-2' },\n    { url: 'http://www.example.com/page-3' },\n]);\n\n// Run the crawler\nawait crawler.run();\n"),(0,n.kt)("p",null,"Each item in this dataset will be saved to its own file in the following directory:"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-bash"},"{PROJECT_FOLDER}/apify_storage/datasets/default/\n")))}h.isMDXComponent=!0}}]);