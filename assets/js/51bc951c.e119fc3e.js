"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[0],{4633:(e,a,t)=>{t.d(a,{Z:()=>o});var n=t(7294),s=t(3725),r=t(2263);const o=function(e){var a=e.apiPath,t=e.children,o=(0,s.useDocsVersion)(),i=(0,r.default)().siteConfig;return n.createElement("a",{href:i.baseUrl+"api/"+("current"===o.version?"next":o.version)+"/"+a},t)}},1612:(e,a,t)=>{t.r(a),t.d(a,{assets:()=>m,contentTitle:()=>l,default:()=>k,frontMatter:()=>p,metadata:()=>u,toc:()=>c});var n=t(7462),s=t(3366),r=(t(7294),t(3905)),o=t(1736),i=t(4633);var d=["components"],p={id:"map-and-reduce",title:"Dataset Map and Reduce methods"},l=void 0,u={unversionedId:"examples/map-and-reduce",id:"examples/map-and-reduce",title:"Dataset Map and Reduce methods",description:"This example shows an easy use-case of the Dataset map",source:"@site/../docs/examples/map_and_reduce.mdx",sourceDirName:"examples",slug:"/examples/map-and-reduce",permalink:"/apify-ts/docs/next/examples/map-and-reduce",tags:[],version:"current",lastUpdatedBy:"Vlad Frangu",lastUpdatedAt:1646754541,formattedLastUpdatedAt:"3/8/2022",frontMatter:{id:"map-and-reduce",title:"Dataset Map and Reduce methods"},sidebar:"docs",previous:{title:"Forms",permalink:"/apify-ts/docs/next/examples/forms"},next:{title:"Playwright crawler",permalink:"/apify-ts/docs/next/examples/crawlers/playwright/playwright-crawler"}},m={},c=[{value:"Map",id:"map",level:3},{value:"Reduce",id:"reduce",level:3}],h={toc:c};function k(e){var a=e.components,t=(0,s.Z)(e,d);return(0,r.kt)("wrapper",(0,n.Z)({},h,t,{components:a,mdxType:"MDXLayout"}),(0,r.kt)("p",null,"This example shows an easy use-case of the ",(0,r.kt)(i.Z,{apiPath:"core/class/Dataset",mdxType:"VersionedApiLink"},(0,r.kt)("inlineCode",{parentName:"p"},"Dataset"))," ",(0,r.kt)(i.Z,{apiPath:"core/class/Dataset#map",mdxType:"VersionedApiLink"},(0,r.kt)("inlineCode",{parentName:"p"},"map")),"\nand ",(0,r.kt)(i.Z,{apiPath:"core/class/Dataset#reduce",mdxType:"VersionedApiLink"},(0,r.kt)("inlineCode",{parentName:"p"},"reduce"))," methods. Both methods can be used to simplify\nthe dataset results workflow process. Both can be called on the ",(0,r.kt)(i.Z,{apiPath:"core/class/Dataset",mdxType:"VersionedApiLink"},"dataset")," directly."),(0,r.kt)("p",null,"Important to mention is that both methods return a new result (",(0,r.kt)("inlineCode",{parentName:"p"},"map")," returns a new array and ",(0,r.kt)("inlineCode",{parentName:"p"},"reduce")," can return any type) - neither method updates\nthe dataset in any way."),(0,r.kt)("p",null,"Examples for both methods are demonstrated on a simple dataset containing the results scraped from a page: the ",(0,r.kt)("inlineCode",{parentName:"p"},"URL")," and a hypothetical number of\n",(0,r.kt)("inlineCode",{parentName:"p"},"h1")," - ",(0,r.kt)("inlineCode",{parentName:"p"},"h3")," header elements under the ",(0,r.kt)("inlineCode",{parentName:"p"},"headingCount")," key."),(0,r.kt)("p",null,"This data structure is stored in the default dataset under ",(0,r.kt)("inlineCode",{parentName:"p"},"{PROJECT_FOLDER}/apify_storage/datasets/default/"),". If you want to simulate the\nfunctionality, you can use the ",(0,r.kt)(i.Z,{apiPath:"core/class/Dataset#pushData",mdxType:"VersionedApiLink"},(0,r.kt)("inlineCode",{parentName:"p"},"dataset.pushData()")),"\nmethod to save the example ",(0,r.kt)("inlineCode",{parentName:"p"},"JSON array")," to your dataset."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-json"},'[\n    {\n        "url": "https://apify.com/",\n        "headingCount": 11\n    },\n    {\n        "url": "https://apify.com/storage",\n        "headingCount": 8\n    },\n    {\n        "url": "https://apify.com/proxy",\n        "headingCount": 4\n    }\n]\n')),(0,r.kt)("h3",{id:"map"},"Map"),(0,r.kt)("p",null,"The dataset ",(0,r.kt)("inlineCode",{parentName:"p"},"map")," method is very similar to standard Array mapping methods. It produces a new array of values by mapping each value in the existing\narray through a transformation function and an options parameter."),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"map")," method used to check if are there more than 5 header elements on each page:"),(0,r.kt)(o.Z,{className:"language-js",mdxType:"CodeBlock"},"import { Dataset, KeyValueStore } from '@crawlers/core';\n\nconst dataset = await Dataset.open();\nconst keyValueStore = await KeyValueStore.open();\n\n// calling map function and filtering through mapped items\nconst moreThan5headers = (await dataset.map((item) => item.headingCount)).filter((count) => count > 5);\n\n// saving result of map to default Key-value store\nawait keyValueStore.setValue('pages_with_more_than_5_headers', moreThan5headers);\n"),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"moreThan5headers")," variable is an array of ",(0,r.kt)("inlineCode",{parentName:"p"},"headingCount")," attributes where the number of headers is greater than 5."),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"map")," method's result value saved to the ",(0,r.kt)(i.Z,{apiPath:"core/class/KeyValueStore",mdxType:"VersionedApiLink"},(0,r.kt)("inlineCode",{parentName:"p"},"key-value store"))," should be:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-javascript"},"[11, 8]\n")),(0,r.kt)("h3",{id:"reduce"},"Reduce"),(0,r.kt)("p",null,"The dataset ",(0,r.kt)("inlineCode",{parentName:"p"},"reduce")," method does not produce a new array of values - it reduces a list of values down to a single value. The method iterates through\nthe items in the dataset using the ",(0,r.kt)(i.Z,{apiPath:"core/class/Dataset#reduce",mdxType:"VersionedApiLink"},(0,r.kt)("inlineCode",{parentName:"p"},"memo")," argument"),". After performing the necessary\ncalculation, the ",(0,r.kt)("inlineCode",{parentName:"p"},"memo")," is sent to the next iteration, while the item just processed is reduced (removed)."),(0,r.kt)("p",null,"Using the ",(0,r.kt)("inlineCode",{parentName:"p"},"reduce")," method to get the total number of headers scraped (all items in the dataset):"),(0,r.kt)(o.Z,{className:"language-js",mdxType:"CodeBlock"},"import { Dataset, KeyValueStore } from '@crawlers/core';\n\nconst dataset = await Dataset.open();\nconst keyValueStore = await KeyValueStore.open();\n\n// calling reduce function and using memo to calculate number of headers\nconst pagesHeadingCount = await dataset.reduce((memo, value) => {\n    return memo += value.headingCount;\n}, 0);\n\n// saving result of map to default Key-value store\nawait keyValueStore.setValue('pages_heading_count', pagesHeadingCount);\n"),(0,r.kt)("p",null,"The original dataset will be reduced to a single value, ",(0,r.kt)("inlineCode",{parentName:"p"},"pagesHeadingCount"),", which contains the count of all headers for all scraped pages (all\ndataset items)."),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"reduce")," method's result value saved to the ",(0,r.kt)(i.Z,{apiPath:"core/class/KeyValueStore",mdxType:"VersionedApiLink"},(0,r.kt)("inlineCode",{parentName:"p"},"key-value store"))," should be:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-javascript"},"23\n")))}k.isMDXComponent=!0}}]);