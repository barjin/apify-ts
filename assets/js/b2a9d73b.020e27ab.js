"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[5319],{4633:(a,e,t)=>{t.d(e,{Z:()=>r});var s=t(7294),d=t(3725),n=t(2263);const r=function(a){var e=a.apiPath,t=a.children,r=(0,d.useDocsVersion)(),i=(0,n.default)().siteConfig;return s.createElement("a",{href:i.baseUrl+"api/"+("current"===r.version?"next":r.version)+"/"+e},t)}},4680:(a,e,t)=>{t.r(e),t.d(e,{assets:()=>u,contentTitle:()=>c,default:()=>h,frontMatter:()=>l,metadata:()=>p,toc:()=>m});var s=t(7462),d=t(3366),n=(t(7294),t(3905)),r=t(1736),i=t(4633);var o=["components"],l={id:"add-data-to-dataset",title:"Add data to dataset"},c=void 0,p={unversionedId:"examples/basics/add-data-to-dataset",id:"examples/basics/add-data-to-dataset",title:"Add data to dataset",description:"This example saves data to the default dataset. If the dataset doesn't exist, it will be created.",source:"@site/../docs/examples/basics/add_data_to_dataset.mdx",sourceDirName:"examples/basics",slug:"/examples/basics/add-data-to-dataset",permalink:"/apify-ts/docs/next/examples/basics/add-data-to-dataset",tags:[],version:"current",lastUpdatedBy:"Martin Ad\xe1mek",lastUpdatedAt:1646757267,formattedLastUpdatedAt:"3/8/2022",frontMatter:{id:"add-data-to-dataset",title:"Add data to dataset"},sidebar:"docs",previous:{title:"Accept user input",permalink:"/apify-ts/docs/next/examples/basics/accept-user-input"},next:{title:"Basic crawler",permalink:"/apify-ts/docs/next/examples/crawlers/basic/basic-crawler"}},u={},m=[],w={toc:m};function h(a){var e=a.components,t=(0,d.Z)(a,o);return(0,n.kt)("wrapper",(0,s.Z)({},w,t,{components:e,mdxType:"MDXLayout"}),(0,n.kt)("p",null,"This example saves data to the default dataset. If the dataset doesn't exist, it will be created.\nYou can save data to custom datasets by using ",(0,n.kt)(i.Z,{apiPath:"core/class/Dataset#open",mdxType:"VersionedApiLink"},(0,n.kt)("inlineCode",{parentName:"p"},"Dataset.open()"))),(0,n.kt)(r.Z,{className:"language-js",mdxType:"CodeBlock"},"import { Dataset, CheerioCrawler } from '@crawlers/cheerio';\n\n// Create a dataset where we will store the results.\nconst dataset = await Dataset.open();\n\nconst crawler = new CheerioCrawler({\n    // Function called for each URL\n    async requestHandler({ request, body }) {\n        // Save data to default dataset\n        await dataset.pushData({\n            url: request.url,\n            html: body,\n        });\n    },\n});\n\nawait crawler.addRequests([\n    { url: 'http://www.example.com/page-1' },\n    { url: 'http://www.example.com/page-2' },\n    { url: 'http://www.example.com/page-3' },\n]);\n\n// Run the crawler\nawait crawler.run();\n"),(0,n.kt)("p",null,"Each item in this dataset will be saved to its own file in the following directory:"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre",className:"language-bash"},"{PROJECT_FOLDER}/apify_storage/datasets/default/\n")))}h.isMDXComponent=!0}}]);